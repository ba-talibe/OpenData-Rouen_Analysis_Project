{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recuperation des donné avec des fonctions asynchrones pour plus de performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import requests\n",
    "import pandas as pd\n",
    "import aiohttp\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def fetch_data(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacount_base_url = f\"https://data.metropole-rouen-normandie.fr/api/explore/v2.1/catalog/datasets/eco-counter-data/records\"\n",
    "counter_location_base_url = f\"https://data.metropole-rouen-normandie.fr/api/explore/v2.1/catalog/datasets/eco-counter-sites/records\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-9' coro=<main() running at /var/folders/v6/gjxkdclj08sbj2vczb74wtxr0000gn/T/ipykernel_959/3572965771.py:74>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "async def get_data_as_dataframe(\n",
    "        limit : int = 50, \n",
    "        offset : int = 0, \n",
    "        select : str = \"\", \n",
    "        where  : str  = \"\",\n",
    "        group_by : str = \"\",\n",
    "        order_by : str = \"\",\n",
    "        refine : dict = {},\n",
    "        exclude : dict = {}\n",
    "        )  -> pd.DataFrame:\n",
    "    \n",
    "\n",
    "    # query = f\"?limit={limit}\" \\\n",
    "    #         f\"&offset={offset}\" \\\n",
    "    query = \"\"\n",
    "    if select != \"\":\n",
    "        query += f\"{'?' if len(query) == 0 else '&'}select={select}\" \n",
    "    \n",
    "    if where != \"\":\n",
    "        query += f\"{'?' if len(query) == 0 else '&'}where={where}\" \n",
    "\n",
    "    if group_by != \"\":\n",
    "        query += f\"{'?' if len(query) == 0 else '&'}group_by={group_by}\" \n",
    "\n",
    "    if order_by != \"\":\n",
    "        query += f\"{'?' if len(query) == 0 else '&'}order_by={order_by}\" \n",
    "\n",
    "    if refine != {}:\n",
    "        for key in refine:\n",
    "            query += f\"{'?' if len(query) == 0 else '&'}refine={key}%3A{refine[key]}\"\n",
    "\n",
    "    if exclude != {}:\n",
    "        for key in exclude:\n",
    "            query += f\"{'?' if len(query) == 0 else '&'}exclude={key}%3A{exclude[key]}\"\n",
    "        \n",
    "    if 0 < limit <= 100:\n",
    "        query += f\"{'?' if len(query) == 0 else '&'}limit={limit}\" \\\n",
    "            f\"&offset={offset}\" \n",
    "        response = requests.get(datacount_base_url + query).json()\n",
    "        total_count = response[\"total_count\"] \n",
    "        data = response[\"results\"]\n",
    "\n",
    "    else:\n",
    "        if limit == 0:\n",
    "            response = requests.get(datacount_base_url + query+ f\"{'?' if len(query) == 0 else '&'}limit=1\").json()\n",
    "            limit = int(response[\"total_count\"])\n",
    "        # le nombre de requete de limité à 100 entrés possible\n",
    "        nbre_request = limit // 100\n",
    "        # le nombre d'entré de la derniere requete\n",
    "        last_limit = limit  % 100\n",
    "        \n",
    "        data = []\n",
    "        start = time.perf_counter()\n",
    "        for idx_req in range(nbre_request):\n",
    "            limit_query = f\"{'?' if len(query) == 0 else '&'}limit={100}\" \\\n",
    "                    f\"&offset={offset + idx_req*100}\"\n",
    "            response = await fetch_data(datacount_base_url + query + limit_query )# requests.get().json() \n",
    "            if \"message\" in response.keys():\n",
    "                print(response)\n",
    "                break\n",
    "            data += response[\"results\"]\n",
    "        \n",
    "        #envoie de la dernier requete\n",
    "        limit_query = f\"{'?' if len(query) == 0 else '&'}limit={last_limit}\" \\\n",
    "                f\"&offset={offset + (nbre_request)*100}\"\n",
    "        response = await fetch_data(datacount_base_url + query + limit_query ) #requests.get(datacount_base_url + query + limit_query).json() \n",
    "        data += response[\"results\"]\n",
    "        print(\"Time\", time.perf_counter - start)\n",
    "        total_count = response[\"total_count\"] \n",
    "    return f\"{time.perf_counter - start}\", pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    time, df = await get_data_as_dataframe(9000)\n",
    "    print(time)\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task( main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-8' coro=<main() running at /var/folders/v6/gjxkdclj08sbj2vczb74wtxr0000gn/T/ipykernel_959/3572965771.py:74>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task( main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
